{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b7739-6f23-45cf-abe5-81a8c7d6658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50fcc65-7e3d-458f-a01c-0135b21ac2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.client import ddl_cluster_scaling_client\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de242485-c265-4d63-afbe-79fba181ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ddl_cluster_scaling_client.get_auth_headers()\n",
    "print(result['Authorization'][0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80565abf-db18-457c-af82-d2a2d2434fdc",
   "metadata": {},
   "source": [
    "## Define Cluster Kind\n",
    "\n",
    "For ray clusters use this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25616bb9-fd3a-43da-86bf-bdafca9a24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster_kind = \"rayclusters\"\n",
    "cluster_kind = \"sparkclusters\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdacf0a1-7525-4aa8-a2d7-7bd2f3231aaa",
   "metadata": {},
   "source": [
    "### Get the cluster status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626dc69d-bf2c-40bf-bf80-0ce17a5ab6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = ddl_cluster_scaling_client.get_cluster_status(cluster_kind=cluster_kind)\n",
    "print('Cluster status')\n",
    "print(json.dumps(j['status'], indent=2, sort_keys=True, ensure_ascii=False))\n",
    "\n",
    "print('Cluster Autoscaling status')\n",
    "print(json.dumps(j['spec']['autoscaling'], indent=2, sort_keys=True, ensure_ascii=False))\n",
    "\n",
    "print('Cluster worker replicas')\n",
    "print(j['spec']['worker']['replicas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370f109c-b5f0-43f8-8552-afdde12d86fc",
   "metadata": {},
   "source": [
    "### Scale the cluster up using HW tier of your choice\n",
    "\n",
    "Now scale up the cluster. You need to provide two parameters:\n",
    "1. `worker_hw_tier_name` - This is optional. You use it to override the HW Tier used to start the cluster for the workers\n",
    "2. `replicas` - This is the number of desired workers. It needs to be less than the `max_workers` for this cluster or it is capped to the \n",
    "`max_workers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36746bee-b49a-4c52-a901-5f027fe2264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = ddl_cluster_scaling_client.scale_cluster(cluster_kind=cluster_kind, worker_hw_tier_name=\"Medium\", replicas=3)\n",
    "json.dumps(j, indent=2, sort_keys=True, ensure_ascii=False)\n",
    "ddl_cluster_scaling_client.wait_until_scaling_complete(cluster_kind=cluster_kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a19142c-1468-46d2-80b7-8ba64aca316b",
   "metadata": {},
   "source": [
    "### Optionally restart the head node\n",
    "\n",
    "With certain clusters (Ray) the api based scaling does not cause the head node UI to correctly reflect the number of workers even though\n",
    "the cluster utilizes all the workers. It is safe to restart the head code as a matter of hygiene. Once restarted it correctly\n",
    "reflect the correct number of workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f603bb-312a-4063-a2c7-899b79a1d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = ddl_cluster_scaling_client.restart_head_node(cluster_kind=cluster_kind)\n",
    "restarts_at = j['started_at']\n",
    "print(restarts_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a17fed-2aae-4939-85f8-0b7d44cf77c4",
   "metadata": {},
   "outputs": [],
   "source": "ddl_cluster_scaling_client.restart_head_node_status(cluster_kind=cluster_kind, restarted_since=restarts_at)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a8bb4-2fef-4058-a1e8-b00c77f65fa2",
   "metadata": {},
   "outputs": [],
   "source": "ddl_cluster_scaling_client.wait_until_node_restarted(cluster_kind=cluster_kind, restarted_since=restarts_at)"
  },
  {
   "cell_type": "markdown",
   "id": "0160b451-bbba-4d3c-8ce1-9e616d2a7566",
   "metadata": {},
   "source": [
    "### Use the cluster\n",
    "\n",
    "Having fully scaled the cluster to your requirements, use your cluster. Run your hyper-parameter tuning, Deepspeed based LLM\n",
    "fine tuning, large Spark queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df4ca74-ae2b-48e8-a1ca-2b39cf4d8aaf",
   "metadata": {},
   "source": [
    "### Scale Down Cluster\n",
    "\n",
    "Having finished your work, scale down the cluster. You need to provide two parameters:\n",
    "1. `worker_hw_tier_name` - This is optional. You use it to override the HW Tier used to scale the cluster. It is recommended. Use the smallest hw_tier permitted for this cluster type. Domino does not allow you to scale down your cluster to 0. This capability is provided so that if you have used an expensive HW tier for your worker nodes (Ex. GPU Tiers), when you scale down the cluster to 1 worker you can avoid paying for the expensive tier.\n",
    " \n",
    "2. `replicas` - This is the number of desired workers. It needs to be more than or equal to the `min_workers` for this cluster \n",
    "or it is capped to `min_workers`. Always start your cluster so that minimum workers is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549cd30e-7397-4d74-aa4a-d9e10cd26425",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = ddl_cluster_scaling_client.scale_cluster(cluster_kind=cluster_kind, worker_hw_tier_name=\"Small\", replicas=1)\n",
    "json.dumps(j, indent=2, sort_keys=True, ensure_ascii=False)\n",
    "ddl_cluster_scaling_client.wait_until_scaling_complete(cluster_kind=cluster_kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07343e1-711d-4f48-89ec-a4e08238716d",
   "metadata": {},
   "source": [
    "### Optionally restart the head node again\n",
    "\n",
    "This is a good practice in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94d772-41f4-4ca8-a4d6-2ecf7d5c54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = ddl_cluster_scaling_client.restart_head_node(cluster_kind=cluster_kind)\n",
    "restarts_at = j['started_at']\n",
    "print(restarts_at)\n",
    "ddl_cluster_scaling_client.restart_head_node_status(cluster_kind=cluster_kind, restarted_since=restarts_at)\n",
    "ddl_cluster_scaling_client.wait_until_node_restarted(cluster_kind=cluster_kind, restarted_since=restarts_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9b144-a913-491c-a7fb-224a06d350c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
